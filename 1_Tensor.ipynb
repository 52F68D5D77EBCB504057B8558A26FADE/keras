{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf # 관례적으로 tf라는 별칭을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 케라스의 기반이 되는 텐서플로는 넘파이(NumPy)의 다차원 배열과 유사한 텐서 프레임워크을 제공합니다.\n",
    "# 넘파이의 다차원 배열과 텐서플로의 텐서의 차이\n",
    "# 1. 텐서플로는 GPU와 TPU 같은 하드웨어 가속기를 사용할 수 있습니다.\n",
    "# 2. 텐서플로는 임의의 미분 가능 텐서 표현의 그레이디언트를 자동으로 계산합니다.\n",
    "# 3. 텐서플로 계산은 단일 머신에 있는 여러 개의 장치나 머신에 분산할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 1. 텐서의 종류와 생성\n",
    "# 1-1. 0차원 텐서\n",
    "# 하나의 숫자만을 저장하고 있는 텐서로 스칼라(scalar)라고도 합니다.\n",
    "x = tf.constant(1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 1-2. 1차원 텐서\n",
    "# 숫자를 가진 1차원 배열로 벡터(vector)라고도 합니다.\n",
    "# 다차원 배열과 마찬가지로 하나의 축(열)을 가집니다.\n",
    "x = tf.constant([1,2,3,4]) # 파이썬의 리스트를 사용하여 생성할 수 있습니다.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]], shape=(3, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 1-3. 2차원 텐서\n",
    "# 1차원 텐서를 원소로 하는 텐서로 벡터의 배열 또는 행렬(matrix)라고도 합니다.\n",
    "# 다차원 배열과 마찬가지로 2개의 축(행과 열)을 가집니다.\n",
    "x = tf.constant([[1,2,3],\n",
    "                 [4,5,6],\n",
    "                 [7,8,9]])  # 파이썬의 리스트를 사용하여 생성할 수 있습니다.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 1-4. 3차원 텐서\n",
    "# 2차원 텐서를 원소로 하는 텐서입니다. 3차원 이상의 텐서는 이를 지칭할 용어가 없어 그냥\n",
    "# 3차원 텐서라고 합니다.\n",
    "x = tf.constant([[[1,2],\n",
    "                  [3,4]],\n",
    "                 [[5,6],\n",
    "                  [7,8]]])  # 파이썬의 리스트를 사용하여 생성할 수 있습니다.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# 2. 텐서의 속성\n",
    "x = tf.constant([[1,2,3],\n",
    "                 [4,5,6]])\n",
    "\n",
    "print(x.ndim) # 차원 또는 축의 갯수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape) # 형상 정보로 튜플로 표현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype) # 원소 또는 요소의 타입 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 텐서의 다양한 생성 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 3-1. 파이썬의 리스트를 사용\n",
    "l1 = [1, 2, 3, 4]\n",
    "print(tf.constant(l1), \"\\n\")\n",
    "\n",
    "l2 = [[1, 2],\n",
    "      [3, 4]]\n",
    "print(tf.constant(l2), \"\\n\")\n",
    "\n",
    "l3 = [[[1, 2],\n",
    "       [3, 4]],\n",
    "      [[5, 6],\n",
    "       [7, 8]]]\n",
    "print(tf.constant(l3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10.    3.14  1.  ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 참고! 텐서 생성 시, 파이썬이 제공하는 다양한 타입을 저장할 수 있습니다.\n",
    "# 그러나 텐서는 범용 컨테이너가 아닌 수치 연산 전용 컨테이너므로 아래와 같이 서로 다른 타입이\n",
    "# 전달될 경우, 데이터의 손실이 없는 연산 가능한 공통의 타입으로 암시적 변환이 이루어집니다.\n",
    "x = tf.constant([10, 3.14, True])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't convert Python sequence with mixed types to Tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1e022c6bd9a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 따라서 수치 데이터로 변환할 수 없는 데이터가 포함될 경우, 오류가 발생합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hello\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 264\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't convert Python sequence with mixed types to Tensor."
     ]
    }
   ],
   "source": [
    "# 따라서 수치 데이터로 변환할 수 없는 데이터가 포함될 경우, 오류가 발생합니다.\n",
    "y = tf.constant([10, 3.14, True, \"hello\"])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 3. 4.], shape=(4,), dtype=float32)\n",
      "tf.Tensor([10.    3.14  1.  ], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 텐서 생성 시, 원소의 타입을 명시적으로 지정할 수 있습니다.\n",
    "t1 = tf.constant([1,2,3,4], dtype=tf.float32)\n",
    "print(t1)\n",
    "\n",
    "t2 = tf.constant([10, 3.14, True], dtype=tf.float32)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int64) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int64) \n",
      "\n",
      "tf.Tensor(\n",
      "[[[1 2]\n",
      "  [3 4]]\n",
      "\n",
      " [[5 6]\n",
      "  [7 8]]], shape=(2, 2, 2), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 3-2. 넘파이의 다차원을 사용\n",
    "a1 = np.array([1, 2, 3, 4])\n",
    "print(tf.constant(a1), \"\\n\")\n",
    "\n",
    "a2 = np.array([[1, 2],\n",
    "               [3, 4]])\n",
    "print(tf.constant(a2), \"\\n\")\n",
    "\n",
    "a3 = np.array([[[1, 2],\n",
    "                [3, 4]],\n",
    "               [[5, 6],\n",
    "                [7, 8]]])\n",
    "print(tf.constant(a3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tf.Tensor([1 1 1 1 1], shape=(5,), dtype=int32)\n",
      "a: [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# 참고! 텐서를 다차원 배열로 변환할 수 있습니다.\n",
    "t = tf.constant([1, 1, 1, 1, 1])\n",
    "print(\"t:\", t)\n",
    "\n",
    "a = t.numpy()\n",
    "print(\"a:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([0. 0. 0.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 3. 텐서플로 API의 사용\n",
    "\n",
    "# 3-1. zeros: 모든 원소가 0인 텐서를 생성하는 함수\n",
    "\n",
    "# 형상 정보를 튜플 또는 리스트로 전달합니다.\n",
    "print(tf.zeros((3,)))\n",
    "print(tf.zeros([3]))\n",
    "print(tf.zeros(3))     # 1차원 텐서의 경우, 튜플이 아닌 값을 사용할 수 있습니다.\n",
    "\n",
    "print(tf.zeros((2,3)))\n",
    "print(tf.zeros((2,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 0 0], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.zeros(3, dtype=tf.int32)) # 타입을 명시적으로 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([1. 1. 1.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(2, 2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 3-2. ones: 모든 원소가 1인 텐서를 생성하는 함수\n",
    "print(tf.ones((3,)))\n",
    "print(tf.ones([3]))\n",
    "print(tf.ones(3)) # 1차원 텐서의 경우, 튜플이 아닌 값을 사용할 수 있습니다.\n",
    "\n",
    "print(tf.ones((2,3)))\n",
    "print(tf.ones((2,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 1 1], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.ones(3, dtype=tf.int32)) # 타입을 명시적으로 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([9 9 9], shape=(3,), dtype=int32)\n",
      "tf.Tensor([9 9 9], shape=(3,), dtype=int32)\n",
      "tf.Tensor([9 9 9], shape=(3,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[9 9 9]\n",
      " [9 9 9]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[9 9 9]\n",
      "  [9 9 9]]\n",
      "\n",
      " [[9 9 9]\n",
      "  [9 9 9]]], shape=(2, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 3-3. fill: 특정 값을 사용하여 텐서를 생성하는 함수\n",
    "print(tf.fill((3,), 9))\n",
    "print(tf.fill([3], 9))\n",
    "print(tf.fill(3, 9)) # 1차원 텐서의 경우, 튜플이 아닌 값을 사용할 수 있습니다.\n",
    "\n",
    "print(tf.fill((2,3), 9))\n",
    "print(tf.fill((2,2,3), 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fill() got an unexpected keyword argument 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7e93af0ed57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 타입을 명시적으로 지정할 수 없습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fill() got an unexpected keyword argument 'dtype'"
     ]
    }
   ],
   "source": [
    "print(tf.fill((2,3), 9, dtype=tf.float32)) # 타입을 명시적으로 지정할 수 없습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3-4. 기존 텐서의 형상을 사용하여 텐서를 생성할 수 있습니다.\n",
    "t = tf.zeros((2,3))\n",
    "print(tf.zeros_like(t), \"\\n\")\n",
    "print(tf.ones_like(t), \"\\n\")\n",
    "# fill_like는 제공하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-1.3810233  -0.38968164  0.40601113], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 3-5. 난수를 사용하여 텐서를 생성할 수 있습니다.\n",
    "print(tf.random.normal(shape=(3,), mean=0, stddev=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 3 5 7 9], shape=(5,), dtype=int32)\n",
      "tf.Tensor([1.  1.5 2.  2.5 3.  3.5 4.  4.5 5.  5.5 6.  6.5 7.  7.5 8.  8.5 9.  9.5], shape=(18,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 4. 기타\n",
    "\n",
    "# tf.range(start, limit=None, delta=1)\n",
    "print(tf.range(1,10,2))\n",
    "print(tf.range(1,10,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-3.  -1.5  0.   1.5  3. ], shape=(5,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "# tf.linspace(start, stop, num, name=None)\n",
    "print(tf.linspace(-3, 3, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
